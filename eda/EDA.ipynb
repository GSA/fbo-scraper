{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import urllib.request\n",
    "from urllib.request import Request\n",
    "from contextlib import closing\n",
    "import shutil\n",
    "import os\n",
    "from mimetypes import guess_extension\n",
    "import random\n",
    "import re\n",
    "from requests import exceptions\n",
    "import textract\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a Nightly FBO File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nightly_files/fbo_nightly_20180506.json') as f:\n",
    "    json_str = json.load(f)\n",
    "    json_data = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Solicitation Attachments\n",
    "Each notice has a link to its fbo url. Some of those fbo pages have links to solicattion documents. In this section, we'll scrape each notice's page to find and download those solicitation docs.\n",
    "\n",
    "### TO-DO\n",
    " - Ensure that all attachments on fbo pages are found in `<div> class = 'notice_attachment_ro' </div>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(attachment_url, file_name, out_path):\n",
    "    '''\n",
    "    Void function that, given a url to an attachment, downloads and writes it.\n",
    "    \n",
    "    Arguments:\n",
    "        attachment_url (str): the url of the document\n",
    "        file_name (str): what you'd like to save that document as\n",
    "        out_path (str): where you'd like to save that document\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    r = requests.get(attachment_url, timeout=10)\n",
    "    if '/utils/view?id' in attachment_url:\n",
    "        content_type = r.headers['Content-Type']\n",
    "        if content_type == 'application/msword':\n",
    "            extension = '.rtf'\n",
    "        else:\n",
    "            extension = guess_extension(content_type.split()[0].rstrip(\";\"))\n",
    "        # no extensions found for 'application/vnd.openxmlformats-o' content-type\n",
    "        if not extension:\n",
    "            extension = '.docx'\n",
    "        file_name = os.path.join(out_path, file_name+extension)\n",
    "    elif 'ftp://' in attachment_url:\n",
    "        with closing(urllib.request.urlopen(attachment_url)) as r:\n",
    "            file_name = os.path.join(out_path, file_name)\n",
    "            with open(file_name, 'wb') as f:\n",
    "                shutil.copyfileobj(r, f)\n",
    "    else:\n",
    "        file_name = os.path.join(out_path, file_name)\n",
    "    with open(file_name, mode='wb') as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_fbo_attachments(json_data):\n",
    "    '''\n",
    "    Void function that, given json for a single nightly FBO file, visits each notice's\n",
    "    fbo url, finds solicitation documents, and writes them to disk.\n",
    "    \n",
    "    Arguments:\n",
    "        json_data (dict): a dict reprenting json data, ideally as the result of:\n",
    "        ```\n",
    "        with open('fbo_nightly_20180506.json') as f:\n",
    "            json_str = json.load(f)\n",
    "            json_data = json.loads(json_str)\n",
    "        ```\n",
    "    '''\n",
    "    \n",
    "    for k in json_data:\n",
    "        for notice in json_data[k]:\n",
    "            try:\n",
    "                fbo_url = notice['url']\n",
    "            except:\n",
    "                continue\n",
    "            r = requests.get(fbo_url)\n",
    "            r_text = r.text\n",
    "            soup = BeautifulSoup(r_text, \"html.parser\")\n",
    "            attachment_divs = soup.find_all('div', {\"class\": \"notice_attachment_ro\"})\n",
    "            notice['attachments'] = {'url':[], 'text': []}\n",
    "            for i,d in enumerate(attachment_divs):\n",
    "                    attachment_href = d.find('a')['href']\n",
    "                    if '/utils/view?id' in attachment_href:\n",
    "                        attachment_url = 'https://fbo.gov'+attachment_href\n",
    "                    else:\n",
    "                        attachment_url = attachment_href\n",
    "                    notice['attachments']['url'].append(attachment_url)\n",
    "                    file_name = os.path.basename(attachment_url)\n",
    "                    out_path = os.path.join(os.getcwd(),\"attachments\")\n",
    "                    if not os.path.exists(out_path):\n",
    "                        os.makedirs(out_path)\n",
    "                    try:\n",
    "                        write_file(attachment_url, file_name, out_path)\n",
    "                    except exceptions.Timeout:\n",
    "                        print(f\"Connection timed out after 10 seconds.\\n\\t Perhaps inspect:  {attachment_url}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed:  {e}.\\n\\t Perhaps inspect:  {attachment_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fbo_attachments(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Text from Attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attachment_text(attachments_path):\n",
    "    '''\n",
    "    Void function that extracts and writes to a new dir the text from all the files in `attachments_path`.\n",
    "    \n",
    "    Arguments:\n",
    "        attachments_path(str): the directory name where the FBO attachments are located.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    out_path = 'attachment_texts'\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    for file in os.listdir(attachments_path):\n",
    "        if file.startswith('.'):\n",
    "            continue\n",
    "        else:\n",
    "            file_path = os.path.join(attachments_path,file)\n",
    "            try:\n",
    "                b_text = textract.process(file_path, encoding='utf-8')\n",
    "                detected_encoding = chardet.detect(b_text)['encoding']\n",
    "                text = b_text.decode(detected_encoding)\n",
    "                base = os.path.splitext(file)[0]\n",
    "                out_file = base+'.txt'\n",
    "                out = os.path.join(out_path, out_file)\n",
    "                with open(out, 'w') as f:\n",
    "                    f.write(text)\n",
    "            except Exception as e:\n",
    "                print(\"-\"*80)\n",
    "                print(e)\n",
    "                print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_attachment_text('attachments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Unlabeled Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unlabeled_df(unlabeled_data_path):\n",
    "    '''\n",
    "    Create a pandas DataFrame with the unlabled attachment texts.\n",
    "    \n",
    "    Arguments:\n",
    "        unlabeled_data_path (str): the directory for the attachment text files.\n",
    "        \n",
    "    Returns:\n",
    "        unlabeled_df (pandas DataFrame): a dataframe with a column for the file name, \n",
    "                                         the text, and the label, which is np.nan by default.\n",
    "    '''\n",
    "    \n",
    "    texts = []\n",
    "    files = []\n",
    "    labels = []\n",
    "    for file in os.listdir(unlabeled_data_path):\n",
    "        if file.startswith('.'):\n",
    "            continue\n",
    "        else:\n",
    "            files.append(file)\n",
    "            labels.append(np.nan)\n",
    "            file_path = os.path.join(unlabeled_data_path, file)\n",
    "            #use latin1 encoding to be generous with decoding\n",
    "            with open(file_path, 'r', encoding='latin1') as f:\n",
    "                text = f.read()\n",
    "                texts.append(text)\n",
    "    unlabeled_df = pd.DataFrame(data=[files,texts,labels]).transpose()\n",
    "    unlabeled_df.columns = ['file','text','label']\n",
    "    return unlabeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df = create_unlabeled_df('attachment_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DocumentServer.aspx?DocumentId=4281869&amp;FileNam...</td>\n",
       "      <td>FedBizOpps\\n\\nPresolicitation Notice\\n\\n*\\n\\n*...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N40192-18-P-0022_SSJ.txt</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N40192-18-P-0023_SSJBUS.txt</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N4019218P0016_SSJBUS.txt</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>view?id=0ab4be24e7d05feb8d7d1d34d50e8bff.txt</td>\n",
       "      <td>Vendor 1\\n\\n\\n\\nIs there a requirement for thi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  DocumentServer.aspx?DocumentId=4281869&FileNam...   \n",
       "1                           N40192-18-P-0022_SSJ.txt   \n",
       "2                        N40192-18-P-0023_SSJBUS.txt   \n",
       "3                           N4019218P0016_SSJBUS.txt   \n",
       "4       view?id=0ab4be24e7d05feb8d7d1d34d50e8bff.txt   \n",
       "\n",
       "                                                text label  \n",
       "0  FedBizOpps\\n\\nPresolicitation Notice\\n\\n*\\n\\n*...   NaN  \n",
       "1                                                  \n",
       "   NaN  \n",
       "2                                                 \n",
       "\n",
       "   NaN  \n",
       "3                                                 \n",
       "\n",
       "   NaN  \n",
       "4  Vendor 1\\n\\n\\n\\nIs there a requirement for thi...   NaN  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the rows with nothing in the text column are likely pdf images, which are obviously not 508 compliant\n",
    "unlabeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Labeled Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labeled_df(labeled_data_path):\n",
    "    '''\n",
    "    Create a pandas DataFrame with the labled attachment texts.\n",
    "    \n",
    "    Arguments:\n",
    "        labeled_data_path (str): the directory for the labeled attachment text files.\n",
    "        \n",
    "    Returns:\n",
    "        labeled_df (pandas DataFrame): a dataframe with a column for the file name, \n",
    "                                       the text, and the label (green, yellow or red).\n",
    "    '''\n",
    "    \n",
    "    texts = []\n",
    "    files = []\n",
    "    labels = []\n",
    "    for file in os.listdir(labeled_data_path):\n",
    "        if file.startswith('.'):\n",
    "            continue\n",
    "        else:\n",
    "            files.append(file)\n",
    "            label = file.split('_')[0]\n",
    "            labels.append(label)\n",
    "            file_path = os.path.join(labeled_data_path,file)\n",
    "            #use latin1 encoding to be generous with decoding\n",
    "            with open(file_path, 'r', encoding='latin1') as f:\n",
    "                text = f.read()\n",
    "                texts.append(text)\n",
    "    labeled_df = pd.DataFrame(data=[files,texts,labels]).transpose()\n",
    "    labeled_df.columns = ['file','text','label']\n",
    "    return labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = create_labeled_df('labeled_fbo_docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GREEN_10-223-SOL-00051.txt</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GREEN_1055518.txt</td>\n",
       "      <td>\\nStatement of Work -\\n                       ...</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GREEN_1055521.txt</td>\n",
       "      <td>\\n\\nStatement of Work:\\n\\n1.0   BACKGROUND\\nFD...</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GREEN_1057498.txt</td>\n",
       "      <td>\\nAttachment A- High availability equipment (T...</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GREEN_105787.txt</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         file  \\\n",
       "0  GREEN_10-223-SOL-00051.txt   \n",
       "1           GREEN_1055518.txt   \n",
       "2           GREEN_1055521.txt   \n",
       "3           GREEN_1057498.txt   \n",
       "4            GREEN_105787.txt   \n",
       "\n",
       "                                                text  label  \n",
       "0  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...  GREEN  \n",
       "1  \\nStatement of Work -\\n                       ...  GREEN  \n",
       "2  \\n\\nStatement of Work:\\n\\n1.0   BACKGROUND\\nFD...  GREEN  \n",
       "3  \\nAttachment A- High availability equipment (T...  GREEN  \n",
       "4  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...  GREEN  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
